<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE document PUBLIC "+//IDN docutils.sourceforge.net//DTD Docutils Generic//EN//XML" "http://docutils.sourceforge.net/docs/ref/docutils.dtd">
<!-- Generated by Docutils 0.21.2 -->
<document source="/Users/sarinacanelake/openedx/edx-platform/docs/decisions/0003-reduce-bokchoy-testing.rst" translation_progress="{'total': 0, 'translated': 0}" xmlns:c="https://www.sphinx-doc.org/" xmlns:changeset="https://www.sphinx-doc.org/" xmlns:citation="https://www.sphinx-doc.org/" xmlns:cpp="https://www.sphinx-doc.org/" xmlns:http="https://www.sphinx-doc.org/" xmlns:index="https://www.sphinx-doc.org/" xmlns:js="https://www.sphinx-doc.org/" xmlns:math="https://www.sphinx-doc.org/" xmlns:py="https://www.sphinx-doc.org/" xmlns:rst="https://www.sphinx-doc.org/" xmlns:std="https://www.sphinx-doc.org/">
    <section ids="status" names="status">
        <title>Status</title>
        <paragraph>Accepted</paragraph>
    </section>
    <section ids="context" names="context">
        <title>Context</title>
        <paragraph>edx-platform bokchoy tests are slow, flaky and difficult to debug.  A quick assessment of their value shows that they might be more trouble than they are worth.  And that we might get the same benefit with far fewer tests.</paragraph>
        <section ids="baseline-data" names="baseline\ data:">
            <title>Baseline Data:</title>
            <paragraph>This data was collected based on the results of bokchoy tests run across all edx-platform PRs over the last 7 days.</paragraph>
            <bullet_list bullet="*">
                <list_item>
                    <paragraph>Total number of builds: 253(across 106 PRs)</paragraph>
                </list_item>
                <list_item>
                    <paragraph>Failures: 49(across 24 PRs)</paragraph>
                    <bullet_list bullet="*">
                        <list_item>
                            <paragraph>True Failures: 10(across 6 PRs)</paragraph>
                        </list_item>
                        <list_item>
                            <paragraph>Failures that wouldn’t be caught by other test: 3(on 1 PR)</paragraph>
                        </list_item>
                    </bullet_list>
                </list_item>
            </bullet_list>
            <section ids="color" names="color">
                <title>Color</title>
                <definition_list>
                    <definition_list_item>
                        <term>Of the real failures found, there was one PR which had a failure that was only found via bokchoy and a11y tests.</term>
                        <definition>
                            <bullet_list bullet="*">
                                <list_item>
                                    <paragraph>This PR made a JS change which would have broken many pages from loading.</paragraph>
                                </list_item>
                            </bullet_list>
                        </definition>
                    </definition_list_item>
                </definition_list>
            </section>
        </section>
    </section>
    <section ids="recommendation" names="recommendation">
        <title>Recommendation</title>
        <paragraph>Based on the info we have so far, we will only run a suite of smoke tests in bokchoy that ensure the frontend is not entirely broken.</paragraph>
        <paragraph>For the experiment, we will use the a11y bokchoy tests as a simple stand-in for a suite of smoke tests, because it is already a much smaller suite of happy path tests.</paragraph>
        <paragraph>During the experiment, if we find we are missing coverage via a regression, we will first add a missing Python or JavaScript unit test where possible.  Only if this isn’t possible would we add to the smoke suite of bokchoy tests.</paragraph>
        <paragraph>We’ll run in this mode for a month while we collect more data according to the test plan below.  This should give us either the confidence to significantly reduce the number of bokchoy tests or good reasons not to.</paragraph>
        <section ids="test-plan" names="test\ plan">
            <title>Test Plan</title>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>Deactivate bokchoy tests on master and all PRs but leave a11y tests running.</paragraph>
                </list_item>
            </enumerated_list>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>The a11y tests will act as a proxy for the small number of UI tests that would catch most major issues.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>Collect data on which issues bokchoy would have caught by running them manually out-of-band from the standard CI/CD process.</paragraph>
                </list_item>
            </enumerated_list>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>We’ll look at the failures on the out-of-band bokchoy job to find any true failures that would be caught by the removed tests.</paragraph>
                    </list_item>
                    <list_item>
                        <paragraph>On a Daily cadence for 1 month.</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <enumerated_list enumtype="arabic" prefix="" suffix=".">
                <list_item>
                    <paragraph>Assess Impact of change.</paragraph>
                </list_item>
            </enumerated_list>
            <block_quote>
                <bullet_list bullet="*">
                    <list_item>
                        <paragraph>We’ll record the number of issues that bokchoy would have detected, when we manually run the bokchoy job out-of-band.
                            * Both True issues and false positives(flakiness).</paragraph>
                    </list_item>
                </bullet_list>
            </block_quote>
            <paragraph>Outcome: Decision on whether or not to reduce the number of bokchoy tests.</paragraph>
        </section>
    </section>
    <section ids="experiment-results" names="experiment\ results">
        <title>Experiment Results</title>
        <paragraph>Bokchoy tests were disabled for PRs for 3 weeks.  In that time only one change went out that was not caught by other test suites.  The change in question did not impact edx.org and was specific how configuration is read into the system.  The bokchoy tests did not detect any other failures that were not caught by other tests.  The <title_reference>PR</title_reference> where we monitored Bokchoy daily has more specific details.</paragraph>
        <target ids="pr" names="pr" refuri="https://github.com/openedx/edx-platform/pull/23682"></target>
    </section>
    <section ids="decision" names="decision">
        <title>Decision</title>
        <paragraph>We initially used the a11y suite as a placeholder for a set of reduced tests.  Given the results of the tests, we will not pull in any tests from the full bokchoy suite and only keep the a11y tests.</paragraph>
    </section>
    <section ids="consequences" names="consequences">
        <title>Consequences</title>
        <bullet_list bullet="*">
            <list_item>
                <paragraph>Bokchoy testing infrastructure will remain off</paragraph>
            </list_item>
            <list_item>
                <paragraph>Bokchoy tests jobs will be removed all together rather than just disabled</paragraph>
            </list_item>
            <list_item>
                <paragraph>All bokchoy code in edx-platform not related to the a11y tests will be removed</paragraph>
            </list_item>
            <list_item>
                <paragraph>Testing Strategy for UI that is not part of a microfrontend
                    * end-to-end smoke tests via the e2e-tests suite should only be for critical happy paths
                    * UI and frontend logic should be tested using UI unit tests(currently Jasmine).
                    * Django backends and rendered HTML should be tested with integration tests that use the <title_reference>Django test client</title_reference></paragraph>
            </list_item>
        </bullet_list>
        <target ids="django-test-client" names="django\ test\ client" refuri="https://docs.djangoproject.com/en/2.2/topics/testing/tools/#the-test-client"></target>
    </section>
</document>
